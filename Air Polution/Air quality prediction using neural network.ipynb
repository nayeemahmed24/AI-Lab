{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCv0tX5QmCd_"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "sns.set()\r\n",
        "from matplotlib import rcParams\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "8BiGtLwwmicL",
        "outputId": "39f26747-2b75-46c2-fd6f-74dca7cf8447"
      },
      "source": [
        "data = pd.read_csv('Combined Weather Data.csv')\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>TM</th>\n",
              "      <th>Tm</th>\n",
              "      <th>SLP</th>\n",
              "      <th>H</th>\n",
              "      <th>VV</th>\n",
              "      <th>V</th>\n",
              "      <th>VM</th>\n",
              "      <th>PM 2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>219.720833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>182.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>154.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.6</td>\n",
              "      <td>15.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1018.7</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.1</td>\n",
              "      <td>20.6</td>\n",
              "      <td>223.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>200.645833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      T    TM   Tm     SLP     H   VV    V    VM      PM 2.5\n",
              "0   7.4   9.8  4.8  1017.6  93.0  0.5  4.3   9.4  219.720833\n",
              "1   7.8  12.7  4.4  1018.5  87.0  0.6  4.4  11.1  182.187500\n",
              "2   6.7  13.4  2.4  1019.4  82.0  0.6  4.8  11.1  154.037500\n",
              "3   8.6  15.5  3.3  1018.7  72.0  0.8  8.1  20.6  223.208333\n",
              "4  12.4  20.9  4.4  1017.3  61.0  1.3  8.7  22.2  200.645833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k89bdfrumuAl",
        "outputId": "d78cbbbe-16e3-45ae-98ca-95f6743190c9"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1093 entries, 0 to 1092\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   T       1093 non-null   float64\n",
            " 1   TM      1093 non-null   float64\n",
            " 2   Tm      1093 non-null   float64\n",
            " 3   SLP     1093 non-null   float64\n",
            " 4   H       1093 non-null   float64\n",
            " 5   VV      1093 non-null   float64\n",
            " 6   V       1093 non-null   float64\n",
            " 7   VM      1093 non-null   float64\n",
            " 8   PM 2.5  1092 non-null   float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 77.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsznWnEAmzeq"
      },
      "source": [
        "data.fillna(method='ffill', inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHi_2ExVnTA-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X = data[['T', 'TM', 'Tm', 'SLP', 'H', 'VV', 'V', 'VM']]\r\n",
        "y = data['PM 2.5']\r\n",
        "\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.10, random_state = 42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PupaVKeQnZ6Y"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Activation\r\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHj4P5wjna59"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='Adam',loss='mse')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JSsxNxlnfWv",
        "outputId": "af021be2-3074-4e56-d199-469382abe964"
      },
      "source": [
        "model.fit(x=X_train,y=y_train,\r\n",
        "          validation_data=(X_val,y_val),\r\n",
        "          batch_size=128,epochs=400)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7472.8901 - val_loss: 7369.1206\n",
            "Epoch 2/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6968.6670 - val_loss: 7360.7422\n",
            "Epoch 3/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7265.0938 - val_loss: 7312.9482\n",
            "Epoch 4/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7046.7492 - val_loss: 7290.6714\n",
            "Epoch 5/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7086.0983 - val_loss: 7269.5449\n",
            "Epoch 6/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6749.5830 - val_loss: 7229.6069\n",
            "Epoch 7/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6894.7626 - val_loss: 7204.0952\n",
            "Epoch 8/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6859.0763 - val_loss: 7171.6978\n",
            "Epoch 9/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6731.8600 - val_loss: 7138.9546\n",
            "Epoch 10/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6630.3495 - val_loss: 7105.8564\n",
            "Epoch 11/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6903.3841 - val_loss: 7103.7227\n",
            "Epoch 12/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6556.5886 - val_loss: 7034.3340\n",
            "Epoch 13/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6699.1605 - val_loss: 7018.9932\n",
            "Epoch 14/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6590.7147 - val_loss: 6957.9849\n",
            "Epoch 15/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6128.9014 - val_loss: 6905.4883\n",
            "Epoch 16/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6792.8704 - val_loss: 6892.0776\n",
            "Epoch 17/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6523.0416 - val_loss: 6789.4478\n",
            "Epoch 18/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6377.5227 - val_loss: 6719.8062\n",
            "Epoch 19/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6229.8808 - val_loss: 6644.0654\n",
            "Epoch 20/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6299.7689 - val_loss: 6578.5928\n",
            "Epoch 21/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6629.9225 - val_loss: 6511.8818\n",
            "Epoch 22/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6145.4797 - val_loss: 6355.7593\n",
            "Epoch 23/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6199.9604 - val_loss: 6264.9849\n",
            "Epoch 24/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6103.4825 - val_loss: 6102.0659\n",
            "Epoch 25/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5669.0758 - val_loss: 5960.5308\n",
            "Epoch 26/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5823.8897 - val_loss: 5787.0386\n",
            "Epoch 27/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5495.4193 - val_loss: 5724.1289\n",
            "Epoch 28/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5584.3228 - val_loss: 5506.7607\n",
            "Epoch 29/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5316.5206 - val_loss: 5324.0723\n",
            "Epoch 30/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5572.6536 - val_loss: 5086.2021\n",
            "Epoch 31/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5062.3519 - val_loss: 5093.3677\n",
            "Epoch 32/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5022.1244 - val_loss: 4747.4365\n",
            "Epoch 33/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4906.3977 - val_loss: 4544.8779\n",
            "Epoch 34/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4867.6217 - val_loss: 4671.3096\n",
            "Epoch 35/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5163.0767 - val_loss: 4778.2192\n",
            "Epoch 36/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5223.0601 - val_loss: 4130.0967\n",
            "Epoch 37/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4489.1717 - val_loss: 3953.9744\n",
            "Epoch 38/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4396.6323 - val_loss: 3967.2729\n",
            "Epoch 39/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4072.3532 - val_loss: 3737.9961\n",
            "Epoch 40/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4120.3464 - val_loss: 3713.1643\n",
            "Epoch 41/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4073.2265 - val_loss: 4257.3633\n",
            "Epoch 42/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4337.8602 - val_loss: 3652.8154\n",
            "Epoch 43/400\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 4097.5055 - val_loss: 3575.2056\n",
            "Epoch 44/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3784.7016 - val_loss: 3765.5283\n",
            "Epoch 45/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4000.0398 - val_loss: 3755.7280\n",
            "Epoch 46/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4173.9715 - val_loss: 3676.1116\n",
            "Epoch 47/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4482.4884 - val_loss: 3566.8467\n",
            "Epoch 48/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4073.0809 - val_loss: 3664.8564\n",
            "Epoch 49/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4088.4904 - val_loss: 3485.8818\n",
            "Epoch 50/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4171.5297 - val_loss: 3679.4646\n",
            "Epoch 51/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3854.4839 - val_loss: 3442.8459\n",
            "Epoch 52/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3876.7144 - val_loss: 3560.8640\n",
            "Epoch 53/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3838.2661 - val_loss: 3491.6809\n",
            "Epoch 54/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4057.4268 - val_loss: 3568.4531\n",
            "Epoch 55/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3821.5509 - val_loss: 3476.2034\n",
            "Epoch 56/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4034.6127 - val_loss: 3419.4675\n",
            "Epoch 57/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3868.1666 - val_loss: 3372.2471\n",
            "Epoch 58/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3994.3111 - val_loss: 3886.9958\n",
            "Epoch 59/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4214.3601 - val_loss: 3483.4443\n",
            "Epoch 60/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4221.0324 - val_loss: 3372.1597\n",
            "Epoch 61/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3664.9598 - val_loss: 3445.4675\n",
            "Epoch 62/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3656.5181 - val_loss: 3312.1387\n",
            "Epoch 63/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3932.2411 - val_loss: 3559.2998\n",
            "Epoch 64/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3668.1858 - val_loss: 3351.9688\n",
            "Epoch 65/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3883.6033 - val_loss: 3275.7458\n",
            "Epoch 66/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3728.3023 - val_loss: 3490.5354\n",
            "Epoch 67/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3862.4706 - val_loss: 3258.8318\n",
            "Epoch 68/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3529.2017 - val_loss: 3289.3335\n",
            "Epoch 69/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3878.6996 - val_loss: 3263.3320\n",
            "Epoch 70/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3580.8185 - val_loss: 3357.8618\n",
            "Epoch 71/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3890.3374 - val_loss: 3330.9038\n",
            "Epoch 72/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3647.5779 - val_loss: 3234.3833\n",
            "Epoch 73/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3999.1079 - val_loss: 3274.9307\n",
            "Epoch 74/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3769.4960 - val_loss: 3263.6340\n",
            "Epoch 75/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3519.1447 - val_loss: 3264.2881\n",
            "Epoch 76/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3338.7209 - val_loss: 3264.7825\n",
            "Epoch 77/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3867.8988 - val_loss: 3309.8503\n",
            "Epoch 78/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3640.5686 - val_loss: 3279.3987\n",
            "Epoch 79/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3929.9444 - val_loss: 3171.4368\n",
            "Epoch 80/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3577.2792 - val_loss: 3208.9617\n",
            "Epoch 81/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3773.1060 - val_loss: 3241.1040\n",
            "Epoch 82/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3629.4334 - val_loss: 3154.4358\n",
            "Epoch 83/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3566.8404 - val_loss: 3165.4189\n",
            "Epoch 84/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3786.6326 - val_loss: 3249.9868\n",
            "Epoch 85/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3774.0167 - val_loss: 3413.5181\n",
            "Epoch 86/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3639.3108 - val_loss: 3212.4485\n",
            "Epoch 87/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3823.5470 - val_loss: 3271.8765\n",
            "Epoch 88/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3861.9588 - val_loss: 3172.4443\n",
            "Epoch 89/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3815.7878 - val_loss: 3476.8535\n",
            "Epoch 90/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3718.7768 - val_loss: 3215.7107\n",
            "Epoch 91/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3595.8900 - val_loss: 3124.4070\n",
            "Epoch 92/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3519.7895 - val_loss: 3145.9153\n",
            "Epoch 93/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3555.1176 - val_loss: 3114.1025\n",
            "Epoch 94/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3533.2964 - val_loss: 3159.8049\n",
            "Epoch 95/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3736.3423 - val_loss: 3546.1750\n",
            "Epoch 96/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3772.0758 - val_loss: 3125.0310\n",
            "Epoch 97/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3646.2351 - val_loss: 3126.0308\n",
            "Epoch 98/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3695.1868 - val_loss: 3274.1006\n",
            "Epoch 99/400\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3478.2558 - val_loss: 3129.0049\n",
            "Epoch 100/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3768.7359 - val_loss: 3122.9170\n",
            "Epoch 101/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3711.3258 - val_loss: 3449.4656\n",
            "Epoch 102/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3961.8510 - val_loss: 3145.2175\n",
            "Epoch 103/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3641.8641 - val_loss: 3089.1670\n",
            "Epoch 104/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3894.4626 - val_loss: 3102.0242\n",
            "Epoch 105/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3959.6119 - val_loss: 3429.1821\n",
            "Epoch 106/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3766.7472 - val_loss: 3124.2368\n",
            "Epoch 107/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3700.8789 - val_loss: 3051.4451\n",
            "Epoch 108/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3648.1125 - val_loss: 3097.6912\n",
            "Epoch 109/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3864.0870 - val_loss: 3123.8850\n",
            "Epoch 110/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3467.4099 - val_loss: 3101.7742\n",
            "Epoch 111/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3543.0081 - val_loss: 3164.7000\n",
            "Epoch 112/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3476.3627 - val_loss: 3198.3347\n",
            "Epoch 113/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3618.7695 - val_loss: 3055.5654\n",
            "Epoch 114/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3467.6309 - val_loss: 3396.0735\n",
            "Epoch 115/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3557.2791 - val_loss: 3079.6436\n",
            "Epoch 116/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3664.9399 - val_loss: 3363.3164\n",
            "Epoch 117/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3469.8901 - val_loss: 3065.8647\n",
            "Epoch 118/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3621.3350 - val_loss: 3052.2390\n",
            "Epoch 119/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3996.4207 - val_loss: 3536.1174\n",
            "Epoch 120/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3707.5186 - val_loss: 3061.1299\n",
            "Epoch 121/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3509.1940 - val_loss: 3046.8718\n",
            "Epoch 122/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3591.1832 - val_loss: 3056.8506\n",
            "Epoch 123/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3454.0979 - val_loss: 3268.6990\n",
            "Epoch 124/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3672.8706 - val_loss: 3045.3645\n",
            "Epoch 125/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3720.0132 - val_loss: 3085.3757\n",
            "Epoch 126/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3422.2460 - val_loss: 3121.9949\n",
            "Epoch 127/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3787.3643 - val_loss: 3070.3523\n",
            "Epoch 128/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3665.3502 - val_loss: 3092.1184\n",
            "Epoch 129/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3534.3349 - val_loss: 3179.3372\n",
            "Epoch 130/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3808.2900 - val_loss: 3167.6125\n",
            "Epoch 131/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3607.6950 - val_loss: 3052.3462\n",
            "Epoch 132/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3507.4951 - val_loss: 3041.9136\n",
            "Epoch 133/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3390.5372 - val_loss: 3314.5657\n",
            "Epoch 134/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3436.7726 - val_loss: 3081.8230\n",
            "Epoch 135/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3679.4849 - val_loss: 3042.1580\n",
            "Epoch 136/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3697.9468 - val_loss: 3085.3694\n",
            "Epoch 137/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3428.2442 - val_loss: 3011.1023\n",
            "Epoch 138/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3457.6039 - val_loss: 2999.0579\n",
            "Epoch 139/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3629.2527 - val_loss: 3041.3157\n",
            "Epoch 140/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3457.5600 - val_loss: 3132.3882\n",
            "Epoch 141/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3616.8428 - val_loss: 3068.4351\n",
            "Epoch 142/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3217.8323 - val_loss: 2983.6411\n",
            "Epoch 143/400\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3702.2002 - val_loss: 2990.7986\n",
            "Epoch 144/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3716.6176 - val_loss: 3197.5830\n",
            "Epoch 145/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3532.9297 - val_loss: 3087.7083\n",
            "Epoch 146/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3797.0842 - val_loss: 2992.4031\n",
            "Epoch 147/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3849.0822 - val_loss: 3012.9446\n",
            "Epoch 148/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3497.7379 - val_loss: 3105.6382\n",
            "Epoch 149/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3855.5650 - val_loss: 2992.6255\n",
            "Epoch 150/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3374.1874 - val_loss: 2983.2571\n",
            "Epoch 151/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3683.5516 - val_loss: 3094.3542\n",
            "Epoch 152/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3574.4365 - val_loss: 3358.8630\n",
            "Epoch 153/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3651.3463 - val_loss: 2969.5073\n",
            "Epoch 154/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3524.8519 - val_loss: 2970.0237\n",
            "Epoch 155/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3754.1937 - val_loss: 2991.6565\n",
            "Epoch 156/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3522.0255 - val_loss: 3000.8596\n",
            "Epoch 157/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3690.8641 - val_loss: 3145.2312\n",
            "Epoch 158/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3580.7412 - val_loss: 2959.1677\n",
            "Epoch 159/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3482.9762 - val_loss: 3101.2969\n",
            "Epoch 160/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3681.5046 - val_loss: 3015.5337\n",
            "Epoch 161/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3307.4578 - val_loss: 3071.8713\n",
            "Epoch 162/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3650.5424 - val_loss: 3199.6116\n",
            "Epoch 163/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3671.4420 - val_loss: 2962.2139\n",
            "Epoch 164/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3562.9787 - val_loss: 2964.9233\n",
            "Epoch 165/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3385.1493 - val_loss: 2988.2866\n",
            "Epoch 166/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3434.3962 - val_loss: 3001.1228\n",
            "Epoch 167/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3654.2113 - val_loss: 2961.8042\n",
            "Epoch 168/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3397.4003 - val_loss: 3005.8987\n",
            "Epoch 169/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3483.6325 - val_loss: 3076.3855\n",
            "Epoch 170/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3868.3090 - val_loss: 2959.8118\n",
            "Epoch 171/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3620.6524 - val_loss: 2994.4543\n",
            "Epoch 172/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3585.5976 - val_loss: 3028.0632\n",
            "Epoch 173/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3539.9917 - val_loss: 3019.7507\n",
            "Epoch 174/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3490.9914 - val_loss: 2995.6279\n",
            "Epoch 175/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3261.3451 - val_loss: 3047.4839\n",
            "Epoch 176/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3556.7432 - val_loss: 2957.0583\n",
            "Epoch 177/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3553.2477 - val_loss: 3193.9680\n",
            "Epoch 178/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3322.3365 - val_loss: 2932.1064\n",
            "Epoch 179/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3352.7143 - val_loss: 2998.0110\n",
            "Epoch 180/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3591.4037 - val_loss: 3190.8352\n",
            "Epoch 181/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3713.3709 - val_loss: 2944.8218\n",
            "Epoch 182/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3730.8160 - val_loss: 2927.2366\n",
            "Epoch 183/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3421.7866 - val_loss: 3080.8972\n",
            "Epoch 184/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3345.4160 - val_loss: 2915.2441\n",
            "Epoch 185/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3768.6841 - val_loss: 3043.9717\n",
            "Epoch 186/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3620.2411 - val_loss: 2932.6758\n",
            "Epoch 187/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3481.5469 - val_loss: 2973.0474\n",
            "Epoch 188/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3694.1879 - val_loss: 2906.8110\n",
            "Epoch 189/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3290.0843 - val_loss: 2923.4094\n",
            "Epoch 190/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3234.3760 - val_loss: 3083.5134\n",
            "Epoch 191/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3452.0102 - val_loss: 2944.7209\n",
            "Epoch 192/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3753.6191 - val_loss: 2998.6360\n",
            "Epoch 193/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3497.3232 - val_loss: 2988.8367\n",
            "Epoch 194/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3606.2518 - val_loss: 2975.5967\n",
            "Epoch 195/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3402.1132 - val_loss: 2923.9424\n",
            "Epoch 196/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3686.6336 - val_loss: 2953.9189\n",
            "Epoch 197/400\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3561.5228 - val_loss: 2967.2998\n",
            "Epoch 198/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3456.2404 - val_loss: 2922.9927\n",
            "Epoch 199/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3645.3585 - val_loss: 2909.6118\n",
            "Epoch 200/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3657.8185 - val_loss: 3546.8396\n",
            "Epoch 201/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3474.1305 - val_loss: 2918.7966\n",
            "Epoch 202/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3298.8300 - val_loss: 2976.3977\n",
            "Epoch 203/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3675.1361 - val_loss: 3156.6304\n",
            "Epoch 204/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3488.9285 - val_loss: 2921.3071\n",
            "Epoch 205/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3562.0001 - val_loss: 2902.6597\n",
            "Epoch 206/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3510.7613 - val_loss: 3188.3286\n",
            "Epoch 207/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3580.1193 - val_loss: 2892.4778\n",
            "Epoch 208/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3544.0345 - val_loss: 2897.0325\n",
            "Epoch 209/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3447.9024 - val_loss: 2890.1248\n",
            "Epoch 210/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3565.3116 - val_loss: 3182.6389\n",
            "Epoch 211/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3474.6869 - val_loss: 2890.9302\n",
            "Epoch 212/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3530.8721 - val_loss: 2958.5730\n",
            "Epoch 213/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3420.2734 - val_loss: 3082.0852\n",
            "Epoch 214/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3587.9100 - val_loss: 2892.5837\n",
            "Epoch 215/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3337.8327 - val_loss: 2907.8855\n",
            "Epoch 216/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3506.7533 - val_loss: 3226.8418\n",
            "Epoch 217/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3836.9515 - val_loss: 2968.5681\n",
            "Epoch 218/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3368.5888 - val_loss: 2976.3926\n",
            "Epoch 219/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3542.3687 - val_loss: 3164.7256\n",
            "Epoch 220/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3287.8526 - val_loss: 2897.4172\n",
            "Epoch 221/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3227.4617 - val_loss: 2899.8899\n",
            "Epoch 222/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3445.8499 - val_loss: 3061.3008\n",
            "Epoch 223/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3175.1025 - val_loss: 2900.8752\n",
            "Epoch 224/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3570.8086 - val_loss: 2908.2463\n",
            "Epoch 225/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3726.8537 - val_loss: 2962.1287\n",
            "Epoch 226/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3430.0027 - val_loss: 2898.9685\n",
            "Epoch 227/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3694.6596 - val_loss: 3244.6375\n",
            "Epoch 228/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3581.4961 - val_loss: 2909.0103\n",
            "Epoch 229/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3209.7224 - val_loss: 2891.7644\n",
            "Epoch 230/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3461.5500 - val_loss: 3103.9177\n",
            "Epoch 231/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3535.3070 - val_loss: 2979.6633\n",
            "Epoch 232/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3505.4057 - val_loss: 2859.5625\n",
            "Epoch 233/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3614.4592 - val_loss: 3021.7581\n",
            "Epoch 234/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3811.7740 - val_loss: 2907.4451\n",
            "Epoch 235/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3130.1777 - val_loss: 2894.5898\n",
            "Epoch 236/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3187.3997 - val_loss: 2942.7859\n",
            "Epoch 237/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3320.4150 - val_loss: 2879.9741\n",
            "Epoch 238/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3375.7328 - val_loss: 2905.5176\n",
            "Epoch 239/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3561.4997 - val_loss: 3013.5806\n",
            "Epoch 240/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3217.8475 - val_loss: 2871.6521\n",
            "Epoch 241/400\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3514.9749 - val_loss: 2892.0852\n",
            "Epoch 242/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3599.6417 - val_loss: 2851.4978\n",
            "Epoch 243/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3299.2796 - val_loss: 2867.0312\n",
            "Epoch 244/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3619.3971 - val_loss: 2866.9924\n",
            "Epoch 245/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3221.5457 - val_loss: 2929.2698\n",
            "Epoch 246/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3273.0044 - val_loss: 2842.9138\n",
            "Epoch 247/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3240.3657 - val_loss: 3040.5012\n",
            "Epoch 248/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3489.5199 - val_loss: 2960.4460\n",
            "Epoch 249/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3181.7574 - val_loss: 2886.1021\n",
            "Epoch 250/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3506.3494 - val_loss: 2873.5725\n",
            "Epoch 251/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3424.4806 - val_loss: 2877.0056\n",
            "Epoch 252/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3387.2321 - val_loss: 3084.0583\n",
            "Epoch 253/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3502.6195 - val_loss: 2901.7551\n",
            "Epoch 254/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3538.5406 - val_loss: 3065.6118\n",
            "Epoch 255/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3457.4346 - val_loss: 2850.5847\n",
            "Epoch 256/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3500.8311 - val_loss: 2834.8926\n",
            "Epoch 257/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3580.3900 - val_loss: 2881.7324\n",
            "Epoch 258/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3633.7976 - val_loss: 2969.9587\n",
            "Epoch 259/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3524.1219 - val_loss: 2943.6958\n",
            "Epoch 260/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3564.5110 - val_loss: 2851.2019\n",
            "Epoch 261/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3302.1898 - val_loss: 2851.2686\n",
            "Epoch 262/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3436.6245 - val_loss: 2944.9429\n",
            "Epoch 263/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3225.9209 - val_loss: 2826.4624\n",
            "Epoch 264/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3446.0553 - val_loss: 3018.8347\n",
            "Epoch 265/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3339.4476 - val_loss: 2860.8496\n",
            "Epoch 266/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3378.3810 - val_loss: 2850.1428\n",
            "Epoch 267/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3361.6370 - val_loss: 2903.7896\n",
            "Epoch 268/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3110.2336 - val_loss: 2824.4763\n",
            "Epoch 269/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3592.0493 - val_loss: 2836.3486\n",
            "Epoch 270/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3205.9562 - val_loss: 3013.5017\n",
            "Epoch 271/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3400.3702 - val_loss: 2962.2241\n",
            "Epoch 272/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3493.8351 - val_loss: 2820.8704\n",
            "Epoch 273/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3376.5205 - val_loss: 2827.5334\n",
            "Epoch 274/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3204.8318 - val_loss: 2824.5398\n",
            "Epoch 275/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3513.7721 - val_loss: 2901.9475\n",
            "Epoch 276/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3498.4373 - val_loss: 2835.1948\n",
            "Epoch 277/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3320.7871 - val_loss: 2878.5603\n",
            "Epoch 278/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3387.4188 - val_loss: 2811.6577\n",
            "Epoch 279/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3561.1459 - val_loss: 2974.6196\n",
            "Epoch 280/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3527.9873 - val_loss: 2827.3535\n",
            "Epoch 281/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3742.3061 - val_loss: 2860.5122\n",
            "Epoch 282/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3435.9854 - val_loss: 2853.3640\n",
            "Epoch 283/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3136.8462 - val_loss: 2808.0544\n",
            "Epoch 284/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3407.5404 - val_loss: 2854.7581\n",
            "Epoch 285/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3385.7423 - val_loss: 2831.9211\n",
            "Epoch 286/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3502.4880 - val_loss: 2813.8877\n",
            "Epoch 287/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3408.8610 - val_loss: 3169.0940\n",
            "Epoch 288/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3627.9922 - val_loss: 2822.5920\n",
            "Epoch 289/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3271.4602 - val_loss: 2807.9302\n",
            "Epoch 290/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3486.3856 - val_loss: 2821.9233\n",
            "Epoch 291/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3448.9270 - val_loss: 2904.7498\n",
            "Epoch 292/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3138.4248 - val_loss: 2803.6882\n",
            "Epoch 293/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3269.5643 - val_loss: 3110.5415\n",
            "Epoch 294/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3864.1331 - val_loss: 2913.6611\n",
            "Epoch 295/400\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3304.2823 - val_loss: 2813.9382\n",
            "Epoch 296/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3533.4174 - val_loss: 3067.4177\n",
            "Epoch 297/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3348.2234 - val_loss: 2905.1372\n",
            "Epoch 298/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3166.3086 - val_loss: 2802.0823\n",
            "Epoch 299/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3280.2806 - val_loss: 2800.1111\n",
            "Epoch 300/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3423.6628 - val_loss: 2821.9202\n",
            "Epoch 301/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3334.5283 - val_loss: 2805.0398\n",
            "Epoch 302/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3590.5876 - val_loss: 2767.2651\n",
            "Epoch 303/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3394.9254 - val_loss: 3042.7854\n",
            "Epoch 304/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3490.4168 - val_loss: 2914.3345\n",
            "Epoch 305/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3344.2737 - val_loss: 2890.3440\n",
            "Epoch 306/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3572.8380 - val_loss: 2774.6982\n",
            "Epoch 307/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3364.8341 - val_loss: 2896.4165\n",
            "Epoch 308/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3261.7878 - val_loss: 2837.3337\n",
            "Epoch 309/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3251.4277 - val_loss: 2859.0923\n",
            "Epoch 310/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3238.2020 - val_loss: 2797.1619\n",
            "Epoch 311/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3576.0819 - val_loss: 3068.1956\n",
            "Epoch 312/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3207.7270 - val_loss: 2941.7495\n",
            "Epoch 313/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3566.8585 - val_loss: 2798.2900\n",
            "Epoch 314/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3425.8093 - val_loss: 2803.5122\n",
            "Epoch 315/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3355.8294 - val_loss: 2803.5083\n",
            "Epoch 316/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3498.6335 - val_loss: 3060.2007\n",
            "Epoch 317/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3444.5666 - val_loss: 2939.0715\n",
            "Epoch 318/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3390.3016 - val_loss: 2783.9250\n",
            "Epoch 319/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3339.8565 - val_loss: 2850.9658\n",
            "Epoch 320/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3661.8438 - val_loss: 2959.1597\n",
            "Epoch 321/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3502.8028 - val_loss: 2768.9917\n",
            "Epoch 322/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3318.0430 - val_loss: 2783.4585\n",
            "Epoch 323/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3138.1501 - val_loss: 2797.8354\n",
            "Epoch 324/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3305.9188 - val_loss: 2900.6580\n",
            "Epoch 325/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3373.5564 - val_loss: 2908.0618\n",
            "Epoch 326/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3290.2534 - val_loss: 2773.7239\n",
            "Epoch 327/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3499.1531 - val_loss: 2762.0256\n",
            "Epoch 328/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3484.4776 - val_loss: 2892.6042\n",
            "Epoch 329/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3426.7731 - val_loss: 2912.3494\n",
            "Epoch 330/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3260.1701 - val_loss: 2772.6318\n",
            "Epoch 331/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3151.9368 - val_loss: 2744.0596\n",
            "Epoch 332/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3173.4015 - val_loss: 2828.5740\n",
            "Epoch 333/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3255.4576 - val_loss: 2776.3899\n",
            "Epoch 334/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3394.5477 - val_loss: 2756.9763\n",
            "Epoch 335/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3478.3734 - val_loss: 3075.6772\n",
            "Epoch 336/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3420.4717 - val_loss: 2752.7085\n",
            "Epoch 337/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3417.7947 - val_loss: 2748.5925\n",
            "Epoch 338/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3271.8507 - val_loss: 2832.8113\n",
            "Epoch 339/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3413.4109 - val_loss: 2863.7402\n",
            "Epoch 340/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3497.3608 - val_loss: 2746.5620\n",
            "Epoch 341/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3603.0088 - val_loss: 2786.9473\n",
            "Epoch 342/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3213.8312 - val_loss: 2861.2168\n",
            "Epoch 343/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3422.6022 - val_loss: 2750.4968\n",
            "Epoch 344/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3406.0061 - val_loss: 2874.2295\n",
            "Epoch 345/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3558.2903 - val_loss: 3081.4585\n",
            "Epoch 346/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3535.5555 - val_loss: 3313.6228\n",
            "Epoch 347/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3634.5069 - val_loss: 3005.4143\n",
            "Epoch 348/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3474.2089 - val_loss: 2854.3826\n",
            "Epoch 349/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3417.5039 - val_loss: 2989.3647\n",
            "Epoch 350/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3118.8153 - val_loss: 2756.8989\n",
            "Epoch 351/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3308.2912 - val_loss: 2821.4919\n",
            "Epoch 352/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3342.4467 - val_loss: 2916.6509\n",
            "Epoch 353/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3222.8044 - val_loss: 2771.5369\n",
            "Epoch 354/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3470.2289 - val_loss: 2763.5366\n",
            "Epoch 355/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3602.4697 - val_loss: 2912.4087\n",
            "Epoch 356/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3312.6781 - val_loss: 2727.2949\n",
            "Epoch 357/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2997.6935 - val_loss: 2813.5935\n",
            "Epoch 358/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3522.1720 - val_loss: 2766.1387\n",
            "Epoch 359/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3385.5247 - val_loss: 2762.3809\n",
            "Epoch 360/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3455.4566 - val_loss: 2860.8384\n",
            "Epoch 361/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3501.8772 - val_loss: 2949.3088\n",
            "Epoch 362/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3399.2396 - val_loss: 2741.6626\n",
            "Epoch 363/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3403.3482 - val_loss: 2957.1526\n",
            "Epoch 364/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3460.3187 - val_loss: 2766.9849\n",
            "Epoch 365/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3377.6876 - val_loss: 2861.3538\n",
            "Epoch 366/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3532.4382 - val_loss: 2793.3945\n",
            "Epoch 367/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3113.3043 - val_loss: 2774.2634\n",
            "Epoch 368/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3289.8914 - val_loss: 2777.9207\n",
            "Epoch 369/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3189.1366 - val_loss: 2739.7288\n",
            "Epoch 370/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3287.3628 - val_loss: 2990.5474\n",
            "Epoch 371/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3289.9504 - val_loss: 2729.8523\n",
            "Epoch 372/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3316.7702 - val_loss: 2740.6162\n",
            "Epoch 373/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3297.7150 - val_loss: 2828.6108\n",
            "Epoch 374/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3189.8595 - val_loss: 2761.2664\n",
            "Epoch 375/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3313.1942 - val_loss: 2840.2739\n",
            "Epoch 376/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3031.8006 - val_loss: 2786.4116\n",
            "Epoch 377/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3188.7207 - val_loss: 2901.0232\n",
            "Epoch 378/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3505.2326 - val_loss: 2728.5205\n",
            "Epoch 379/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3511.2035 - val_loss: 2733.6597\n",
            "Epoch 380/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3085.2281 - val_loss: 2844.0276\n",
            "Epoch 381/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3550.3139 - val_loss: 2925.3250\n",
            "Epoch 382/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3560.0703 - val_loss: 2708.3779\n",
            "Epoch 383/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3506.7469 - val_loss: 2707.8960\n",
            "Epoch 384/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3506.8440 - val_loss: 2829.5398\n",
            "Epoch 385/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2969.1638 - val_loss: 2790.8074\n",
            "Epoch 386/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3186.4762 - val_loss: 2707.6042\n",
            "Epoch 387/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3329.2390 - val_loss: 2688.2766\n",
            "Epoch 388/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3260.8724 - val_loss: 2896.2747\n",
            "Epoch 389/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3280.2684 - val_loss: 2857.0015\n",
            "Epoch 390/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3197.4948 - val_loss: 2706.2742\n",
            "Epoch 391/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3205.1877 - val_loss: 2705.6978\n",
            "Epoch 392/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3346.8455 - val_loss: 2742.4016\n",
            "Epoch 393/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3548.4450 - val_loss: 3035.3154\n",
            "Epoch 394/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3208.1981 - val_loss: 2713.6985\n",
            "Epoch 395/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3326.9372 - val_loss: 2710.1716\n",
            "Epoch 396/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3354.5690 - val_loss: 2764.2258\n",
            "Epoch 397/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3378.4639 - val_loss: 2739.9839\n",
            "Epoch 398/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3508.2105 - val_loss: 2721.0603\n",
            "Epoch 399/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3153.1263 - val_loss: 2814.2046\n",
            "Epoch 400/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3355.4283 - val_loss: 2694.3721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb600e58d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQMPzWeHnkkq"
      },
      "source": [
        "y_pred = model.predict(X_val)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "WdQMg3i0nvyq",
        "outputId": "201b90b1-0b28-47cd-81a1-b11183ad695a"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "print('MAE:', metrics.mean_absolute_error(y_val, y_pred))  \r\n",
        "print('MSE:', metrics.mean_squared_error(y_val, y_pred))  \r\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\r\n",
        "print('VarScore:',metrics.explained_variance_score(y_val,y_pred))\r\n",
        "# Visualizing Our predictions\r\n",
        "fig = plt.figure(figsize=(10,5))\r\n",
        "plt.scatter(y_val,y_pred)\r\n",
        "# Perfect predictions\r\n",
        "plt.plot(y_val,y_val,'r')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 36.231323260683\n",
            "MSE: 2694.3720494283943\n",
            "RMSE: 51.90734099747736\n",
            "VarScore: 0.639808638416522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ffb5c8cf7b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "wpCDXo83nw6s",
        "outputId": "624afa7c-4e39-4e20-d5cb-6cb4350eb0f5"
      },
      "source": [
        "y = np.array(y_val)\r\n",
        "y_p = np.array(y_pred).flatten()\r\n",
        "df = pd.DataFrame({\"Test Data\": y, \"Predicted Data\": y_p})\r\n",
        "df.head(100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Data</th>\n",
              "      <th>Predicted Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.791667</td>\n",
              "      <td>52.370628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.333333</td>\n",
              "      <td>51.948792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>97.291667</td>\n",
              "      <td>64.520142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.583333</td>\n",
              "      <td>36.659176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>284.795833</td>\n",
              "      <td>227.692261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>154.037500</td>\n",
              "      <td>196.629974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>82.833333</td>\n",
              "      <td>63.480015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>93.500000</td>\n",
              "      <td>74.934715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>120.208333</td>\n",
              "      <td>179.761276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>77.708333</td>\n",
              "      <td>77.272865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Test Data  Predicted Data\n",
              "0    33.791667       52.370628\n",
              "1    30.333333       51.948792\n",
              "2    97.291667       64.520142\n",
              "3    26.583333       36.659176\n",
              "4   284.795833      227.692261\n",
              "..         ...             ...\n",
              "95  154.037500      196.629974\n",
              "96   82.833333       63.480015\n",
              "97   93.500000       74.934715\n",
              "98  120.208333      179.761276\n",
              "99   77.708333       77.272865\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPJB-1SwnUM5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}